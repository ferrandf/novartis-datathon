{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7grfOm5n-FED"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dti-oEj4-FEE"
   },
   "outputs": [],
   "source": [
    "def _CYME(df: pd.DataFrame) -> float:\n",
    "    \"\"\" Compute the CYME metric, that is 1/2(median(yearly error) + median(monthly error))\"\"\"\n",
    "\n",
    "    yearly_agg = df.groupby(\"cluster_nl\")[[\"target\", \"prediction\"]].sum().reset_index()\n",
    "    yearly_error = abs((yearly_agg[\"target\"] - yearly_agg[\"prediction\"])/yearly_agg[\"target\"]).median()\n",
    "\n",
    "    monthly_error = abs((df[\"target\"] - df[\"prediction\"])/df[\"target\"]).median()\n",
    "\n",
    "    return 1/2*(yearly_error + monthly_error)\n",
    "\n",
    "\n",
    "def _metric(df: pd.DataFrame) -> float:\n",
    "    \"\"\"Compute metric of submission.\n",
    "\n",
    "    :param df: Dataframe with target and 'prediction', and identifiers.\n",
    "    :return: Performance metric\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    # Split 0 actuals - rest\n",
    "    zeros = df[df[\"zero_actuals\"] == 1]\n",
    "    recent = df[df[\"zero_actuals\"] == 0]\n",
    "\n",
    "    # weight for each group\n",
    "    zeros_weight = len(zeros)/len(df)\n",
    "    recent_weight = 1 - zeros_weight\n",
    "\n",
    "    # Compute CYME for each group\n",
    "    return round(recent_weight*_CYME(recent) + zeros_weight*min(1,_CYME(zeros)),8)\n",
    "\n",
    "\n",
    "def compute_metric(submission: pd.DataFrame) -> Tuple[float, float]:\n",
    "    \"\"\"Compute metric.\n",
    "\n",
    "    :param submission: Prediction. Requires columns: ['cluster_nl', 'date', 'target', 'prediction']\n",
    "    :return: Performance metric.\n",
    "    \"\"\"\n",
    "\n",
    "    submission[\"date\"] = pd.to_datetime(submission[\"date\"])\n",
    "    submission = submission[['cluster_nl', 'date', 'target', 'prediction', 'zero_actuals']]\n",
    "\n",
    "    return _metric(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oe_t9NsS-FEF",
    "outputId": "bde6fe67-6ce2-4dd9-9016-01a9e404402a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subset_032C.csv', 'subset_22ED.csv', 'subset_CD59.csv', 'subset_4BA5.csv', 'subset_645F.csv', 'subset_8E53.csv', 'subset_644A.csv', 'subset_66C5.csv', 'subset_96D7.csv', 'subset_6CEE.csv', 'subset_051D.csv', 'subset_980E.csv']\n",
      "Data loaded for therapeutic area 032C\n",
      "Data loaded for therapeutic area 22ED\n",
      "Data loaded for therapeutic area CD59\n",
      "Data loaded for therapeutic area 4BA5\n",
      "Data loaded for therapeutic area 645F\n",
      "Data loaded for therapeutic area 8E53\n",
      "Data loaded for therapeutic area 644A\n",
      "Data loaded for therapeutic area 66C5\n",
      "Data loaded for therapeutic area 96D7\n",
      "Data loaded for therapeutic area 6CEE\n",
      "Data loaded for therapeutic area 051D\n",
      "Data loaded for therapeutic area 980E\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "\n",
    "features_cols = [\n",
    "    \"brand\",\n",
    "    \"che_pc_usd\",\n",
    "    \"che_perc_gdp\",\n",
    "    \"corporation\",\n",
    "    \"country\",\n",
    "    \"launch_date\",\n",
    "    \"drug_id\",\n",
    "    \"ind_launch_date\",\n",
    "    \"indication\",\n",
    "    \"insurance_perc_che\",\n",
    "    \"population\",\n",
    "    \"prev_perc\",\n",
    "    \"price_month\",\n",
    "    \"price_unit\",\n",
    "    \"public_perc_che\",\n",
    "    \"therapeutic_area\",\n",
    "    \"Country_Group\",\n",
    "    \"Price_Group\",\n",
    "    \"indication_number\",\n",
    "    \"avg_price_per_year\",\n",
    "    \"month_number\"\n",
    "]\n",
    "target_col = \"target\"\n",
    "id_col = [\"date\",\"cluster_nl\"]\n",
    "\n",
    "base_dir = os.path.join(os.path.dirname(os.getcwd()), \"dataset\")\n",
    "therap = os.path.join(os.path.dirname(os.getcwd()), \"dataset\", \"therapeutic_area\")\n",
    "# Load datasets\n",
    "# data = pd.read_csv(f\"{base_dir}/train_data.csv\", usecols=features_cols + [target_col] + id_col)\n",
    "data = {}\n",
    "y = {}\n",
    "therapeutic_areas = os.listdir(therap)\n",
    "extracted_parts = [name.split('_')[1].split('.')[0] for name in therapeutic_areas]\n",
    "print(therapeutic_areas)\n",
    "\n",
    "for i in extracted_parts:\n",
    "    data[i] = pd.read_csv(f\"{therap}/subset_{i}.csv\", usecols=features_cols + [target_col] + id_col)\n",
    "    print(f\"Data loaded for therapeutic area {i}\")\n",
    "    y[i] = data[i][target_col]\n",
    "\n",
    "test_data = pd.read_csv(f\"{base_dir}/submission_data_TRY2.csv\", usecols=features_cols + id_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w3TaoaTS-FEH"
   },
   "outputs": [],
   "source": [
    "numeric_features = {}\n",
    "categorical_features = {}\n",
    "for i in extracted_parts:\n",
    "    # convert int64 to float64\n",
    "    data[i] = data[i].astype({\"Country_Group\": \"float64\"})\n",
    "    data[i] = data[i].astype({\"Price_Group\": \"float64\"})\n",
    "    data[i] = data[i].astype({\"indication_number\": \"float64\"})\n",
    "    numeric_features[i] = data[i].select_dtypes(include=['float64']).drop(columns=[target_col], errors='ignore').columns\n",
    "    categorical_features[i] = data[i].select_dtypes(include=['object']).columns\n",
    "\n",
    "test_data = test_data.astype({\"Country_Group\": \"float64\"})\n",
    "test_data = test_data.astype({\"Price_Group\": \"float64\"})\n",
    "test_data = test_data.astype({\"indication_number\": \"float64\"})\n",
    "\n",
    "# Separate numeric and categorical features for imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "usmMQdjP-FEH"
   },
   "outputs": [],
   "source": [
    "X = {}\n",
    "for i in extracted_parts:\n",
    "    # Drop unnecessary columns\n",
    "    X[i] = data[i].drop(columns=[target_col]+[\"cluster_nl\"])\n",
    "\n",
    "X_test = test_data.drop(columns=[\"cluster_nl\"])\n",
    "\n",
    "# Preprocessing pipeline\n",
    "def preprocess_data(X, preprocessor=None, fit=True):\n",
    "    numerical_features = X.select_dtypes(include=['float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['category']).columns\n",
    "\n",
    "    if preprocessor is None:\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numerical_transformer, numerical_features),\n",
    "                ('cat', categorical_transformer, categorical_features)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if fit:\n",
    "        X_transformed = preprocessor.fit_transform(X)\n",
    "    else:\n",
    "        X_transformed = preprocessor.transform(X)\n",
    "\n",
    "    X_transformed = np.array(X_transformed)\n",
    "\n",
    "    return X_transformed, preprocessor\n",
    "\n",
    "# Preprocess data\n",
    "X_transformed = {}\n",
    "for i in extracted_parts:\n",
    "    X_transformed[i], preprocessor = preprocess_data(X[i], fit=True)\n",
    "\n",
    "\n",
    "X_test_transformed = preprocess_data(X_test, preprocessor=preprocessor, fit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dHq-De_4-FEH",
    "outputId": "e91bb5ca-6384-4a3d-bbeb-53186b275a34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_transformed shape for 032C: (2011, 12)\n",
      "X_transformed shape for 22ED: (112, 11)\n",
      "X_transformed shape for CD59: (4578, 12)\n",
      "X_transformed shape for 4BA5: (1628, 12)\n",
      "X_transformed shape for 645F: (589, 12)\n",
      "X_transformed shape for 8E53: (1523, 12)\n",
      "X_transformed shape for 644A: (7579, 12)\n",
      "X_transformed shape for 66C5: (22024, 12)\n",
      "X_transformed shape for 96D7: (45858, 12)\n",
      "X_transformed shape for 6CEE: (11871, 12)\n",
      "X_transformed shape for 051D: (846, 12)\n",
      "X_transformed shape for 980E: (20298, 12)\n"
     ]
    }
   ],
   "source": [
    "X_train = {}\n",
    "X_valid = {}\n",
    "y_train = {}\n",
    "y_valid = {}\n",
    "for i in extracted_parts:\n",
    "    print(f\"X_transformed shape for {i}: {X_transformed[i].shape}\")\n",
    "    X_train[i], X_valid[i], y_train[i], y_valid[i] = train_test_split(X_transformed[i], y[i], test_size=0.05, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1zQShzC-FEH",
    "outputId": "10c07d24-3a72-4fbc-dc91-1c8a16c887fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForest_032C': RandomForestRegressor(random_state=42), 'RandomForest_22ED': RandomForestRegressor(random_state=42), 'RandomForest_CD59': RandomForestRegressor(random_state=42), 'RandomForest_4BA5': RandomForestRegressor(random_state=42), 'RandomForest_645F': RandomForestRegressor(random_state=42), 'RandomForest_8E53': RandomForestRegressor(random_state=42), 'RandomForest_644A': RandomForestRegressor(random_state=42), 'RandomForest_66C5': RandomForestRegressor(random_state=42), 'RandomForest_96D7': RandomForestRegressor(random_state=42), 'RandomForest_6CEE': RandomForestRegressor(random_state=42), 'RandomForest_051D': RandomForestRegressor(random_state=42), 'RandomForest_980E': RandomForestRegressor(random_state=42)}\n"
     ]
    }
   ],
   "source": [
    "# Let's train different models for different therapeutic areas\n",
    "models = {}\n",
    "for i in extracted_parts:\n",
    "    models[f'RandomForest_{i}'] =  RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "print(models)\n",
    "results = {}\n",
    "for i in extracted_parts:\n",
    "    results[i] = 0\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train[i], y_train[i])\n",
    "    scores = cross_val_score(model, X_train[i], y_train[i], scoring='neg_root_mean_squared_error', cv=5)\n",
    "    results[name.split('_')[1].split('.')[0]] = -scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jftJCksW-FEI",
    "outputId": "c6ec0ccd-f87e-414d-e830-da4b1caa00a8"
   },
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2z_9DwfX-FEI",
    "outputId": "8b19bf55-fe95-4554-c9f8-6bf2a6c58f6d"
   },
   "outputs": [],
   "source": [
    "X_test_transformed = preprocess_data(X_test, preprocessor=preprocessor, fit=False)\n",
    "print(X_test_transformed[0])\n",
    "\n",
    "# Ensure indices align between test_data and X_test_transformed\n",
    "X_test_transformed = pd.DataFrame(X_test_transformed[0], index=test_data.index)  # Specify column names if necessary\n",
    "\n",
    "def extract_part(text):\n",
    "    return text.split('_')[2].split('.')[0]\n",
    "\n",
    "X_test_transformed['therapeutic_area'] = test_data['therapeutic_area'].apply(extract_part)\n",
    "print(X_test_transformed)\n",
    "\n",
    "# Initialize a DataFrame to store the results\n",
    "results_final = pd.DataFrame()\n",
    "\n",
    "# Iterate over each therapeutic area\n",
    "for area in models.keys():\n",
    "    keyy = area.split('_')[1]\n",
    "    print(keyy)\n",
    "    # Filter test data for the current therapeutic area\n",
    "    area_indices = X_test_transformed[X_test_transformed['therapeutic_area'] == keyy].index\n",
    "    X_area = X_test_transformed.loc[area_indices].drop('therapeutic_area', axis=1)\n",
    "\n",
    "    # Get the corresponding model\n",
    "    model = models[area]\n",
    "    print(models)\n",
    "\n",
    "    # Make predictions\n",
    "    if not X_area.empty:\n",
    "      predictions = model.predict(X_area)\n",
    "\n",
    "      # Prepare the result DataFrame\n",
    "      test_area = test_data.loc[area_indices]\n",
    "      area_results = pd.DataFrame({\n",
    "          'date': pd.to_datetime(test_area['date']).dt.strftime(\"%m/%d/%Y\"),\n",
    "          'cluster_nl': test_area['cluster_nl'],\n",
    "          'prediction': predictions\n",
    "      })\n",
    "\n",
    "      # Append to the results\n",
    "      results_final = pd.concat([results_final, area_results], ignore_index=True)\n",
    "\n",
    "results_final.to_csv('result.csv', index=False)\n",
    "print(\"Result file saved as 'result.csv'\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
