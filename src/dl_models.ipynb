{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "epochs = 10\n",
    "batch_size=64\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _CYME(df: pd.DataFrame) -> float:\n",
    "    \"\"\" Compute the CYME metric, that is 1/2(median(yearly error) + median(monthly error))\"\"\"\n",
    "\n",
    "    yearly_agg = df.groupby(\"cluster_nl\")[[\"target\", \"prediction\"]].sum().reset_index()\n",
    "    yearly_error = abs((yearly_agg[\"target\"] - yearly_agg[\"prediction\"])/yearly_agg[\"target\"]).median()\n",
    "\n",
    "    monthly_error = abs((df[\"target\"] - df[\"prediction\"])/df[\"target\"]).median()\n",
    "\n",
    "    return 1/2*(yearly_error + monthly_error)\n",
    "\n",
    "\n",
    "def _metric(df: pd.DataFrame) -> float:\n",
    "    \"\"\"Compute metric of submission.\n",
    "\n",
    "    :param df: Dataframe with target and 'prediction', and identifiers.\n",
    "    :return: Performance metric\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    # Split 0 actuals - rest\n",
    "    zeros = df[df[\"zero_actuals\"] == 1]\n",
    "    recent = df[df[\"zero_actuals\"] == 0]\n",
    "\n",
    "    # weight for each group\n",
    "    zeros_weight = len(zeros)/len(df)\n",
    "    recent_weight = 1 - zeros_weight\n",
    "\n",
    "    # Compute CYME for each group\n",
    "    return round(recent_weight*_CYME(recent) + zeros_weight*min(1,_CYME(zeros)),8)\n",
    "\n",
    "\n",
    "def compute_metric(submission: pd.DataFrame) -> Tuple[float, float]:\n",
    "    \"\"\"Compute metric.\n",
    "\n",
    "    :param submission: Prediction. Requires columns: ['cluster_nl', 'date', 'target', 'prediction']\n",
    "    :return: Performance metric.\n",
    "    \"\"\"\n",
    "\n",
    "    submission[\"date\"] = pd.to_datetime(submission[\"date\"])\n",
    "    submission = submission[['cluster_nl', 'date', 'target', 'prediction', 'zero_actuals']]\n",
    "\n",
    "    return _metric(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in dataset directory:\n",
      "/home/ferrandf/novartis-datathon\n",
      "['submission_data.csv', 'train_data.csv', 'First_Clean_train_data.csv', 'train_data_TRY1.csv']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118906 entries, 0 to 118905\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   brand               118906 non-null  object \n",
      " 1   che_pc_usd          118906 non-null  float64\n",
      " 2   che_perc_gdp        118906 non-null  float64\n",
      " 3   cluster_nl          118906 non-null  object \n",
      " 4   corporation         118906 non-null  object \n",
      " 5   country             118906 non-null  object \n",
      " 6   launch_date         118906 non-null  object \n",
      " 7   date                118906 non-null  object \n",
      " 8   drug_id             118906 non-null  object \n",
      " 9   ind_launch_date     118906 non-null  object \n",
      " 10  indication          118906 non-null  object \n",
      " 11  insurance_perc_che  118906 non-null  float64\n",
      " 12  population          118906 non-null  float64\n",
      " 13  prev_perc           118906 non-null  float64\n",
      " 14  price_month         118906 non-null  float64\n",
      " 15  price_unit          118906 non-null  float64\n",
      " 16  public_perc_che     118906 non-null  float64\n",
      " 17  therapeutic_area    118906 non-null  object \n",
      " 18  target              118906 non-null  float64\n",
      "dtypes: float64(9), object(10)\n",
      "memory usage: 17.2+ MB\n",
      "Training data info: None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118906 entries, 0 to 118905\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   brand               118906 non-null  object \n",
      " 1   che_pc_usd          118906 non-null  float64\n",
      " 2   che_perc_gdp        118906 non-null  float64\n",
      " 3   cluster_nl          118906 non-null  object \n",
      " 4   corporation         118906 non-null  object \n",
      " 5   country             118906 non-null  object \n",
      " 6   launch_date         118906 non-null  object \n",
      " 7   date                118906 non-null  object \n",
      " 8   drug_id             118906 non-null  object \n",
      " 9   ind_launch_date     118906 non-null  object \n",
      " 10  indication          118906 non-null  object \n",
      " 11  insurance_perc_che  118906 non-null  float64\n",
      " 12  population          118906 non-null  float64\n",
      " 13  prev_perc           118906 non-null  float64\n",
      " 14  price_month         118906 non-null  float64\n",
      " 15  price_unit          118906 non-null  float64\n",
      " 16  public_perc_che     118906 non-null  float64\n",
      " 17  therapeutic_area    118906 non-null  object \n",
      " 18  target              118906 non-null  float64\n",
      "dtypes: float64(9), object(10)\n",
      "memory usage: 87.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "input_path = \"dataset\"\n",
    "print(\"Files in dataset directory:\")\n",
    "print(os.path.dirname(os.getcwd()))\n",
    "print(os.listdir(os.path.join(os.path.dirname(os.getcwd()), input_path)))\n",
    "\n",
    "features_cols = [\n",
    "    \"brand\", \n",
    "    \"che_pc_usd\", \n",
    "    \"che_perc_gdp\", \n",
    "    \"corporation\", \n",
    "    \"country\", \n",
    "    \"launch_date\", \n",
    "    \"drug_id\", \n",
    "    \"ind_launch_date\", \n",
    "    \"indication\", \n",
    "    \"insurance_perc_che\", \n",
    "    \"population\", \n",
    "    \"prev_perc\", \n",
    "    \"price_month\", \n",
    "    \"price_unit\", \n",
    "    \"public_perc_che\", \n",
    "    \"therapeutic_area\",\n",
    "]\n",
    "target_col = \"target\"\n",
    "id_col = [\"date\",\"cluster_nl\"]\n",
    "\n",
    "base_dir = os.path.join(os.path.dirname(os.getcwd()), input_path)\n",
    "# Load datasets\n",
    "# data = pd.read_csv(f\"{base_dir}/train_data.csv\", usecols=features_cols + [target_col] + id_col)\n",
    "data = pd.read_csv(f\"{base_dir}/train_data_TRY1.csv\", usecols=features_cols + [target_col] + id_col)\n",
    "test_data = pd.read_csv(f\"{base_dir}/submission_data.csv\", usecols=features_cols + id_col)\n",
    "\n",
    "y = data[target_col]\n",
    "\n",
    "# Display dataset informations\n",
    "print(f\"Training data info: {data.info()}\")\n",
    "print(data.info(memory_usage=\"deep\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: Index(['che_pc_usd', 'che_perc_gdp', 'insurance_perc_che', 'population',\n",
      "       'prev_perc', 'price_month', 'price_unit', 'public_perc_che'],\n",
      "      dtype='object')\n",
      "Categorical features: Index(['brand', 'cluster_nl', 'corporation', 'country', 'launch_date', 'date',\n",
      "       'drug_id', 'ind_launch_date', 'indication', 'therapeutic_area'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Separate numeric and categorical features for imputation\n",
    "numeric_features = data.select_dtypes(include=['float64']).drop(columns=[target_col], errors='ignore').columns\n",
    "categorical_features = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(f\"Numeric features: {numeric_features}\")\n",
    "print(f\"Categorical features: {categorical_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.72931342  0.1093513   0.84690232 ...  0.06633365 -0.21597011\n",
      "   0.24331455]\n",
      " [-5.76038552 -4.8459021  -1.9239651  ... -1.35219885  0.11488193\n",
      "  -9.10311876]\n",
      " [-0.72931342  0.1093513   0.84690232 ... -1.35219885  0.93443557\n",
      "   0.24331455]\n",
      " ...\n",
      " [-0.91518872 -0.21468219  0.78305745 ...  0.07397957 -0.21352666\n",
      "   0.54315001]\n",
      " [ 0.78612113  0.76809541 -1.9239651  ...  0.74117745  0.58141327\n",
      "   0.73777625]\n",
      " [-0.91518872 -0.21468219  0.78305745 ... -1.35219885 -0.22195944\n",
      "   0.54315001]]\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "X = data.drop(columns=[target_col]+id_col)\n",
    "X_test = test_data.drop(columns=id_col)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "def preprocess_data(X, preprocessor=None, fit=True):\n",
    "    numerical_features = X.select_dtypes(include=['float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['category']).columns\n",
    "\n",
    "    if preprocessor is None:\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numerical_transformer, numerical_features),\n",
    "                ('cat', categorical_transformer, categorical_features)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if fit:\n",
    "        X_transformed = preprocessor.fit_transform(X)\n",
    "    else:\n",
    "        X_transformed = preprocessor.transform(X)\n",
    "    \n",
    "    X_transformed = np.array(X_transformed)\n",
    "\n",
    "    return X_transformed, preprocessor\n",
    "\n",
    "# Preprocess data\n",
    "X_transformed, preprocessor = preprocess_data(X, fit=True)\n",
    "X_test_transformed, _ = preprocess_data(X_test, preprocessor=preprocessor, fit=False)\n",
    "\n",
    "print(X_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferrandf/novartis-datathon/novartis-venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_transformed, y, test_size=0.05, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['accuracy', 'mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 1.3278 - mae: 0.5128 - mse: 1.3278 - val_accuracy: 0.0024 - val_loss: 0.8726 - val_mae: 0.3426 - val_mse: 0.8726\n",
      "Epoch 2/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 1.0287 - mae: 0.3994 - mse: 1.0287 - val_accuracy: 0.0024 - val_loss: 0.8444 - val_mae: 0.3783 - val_mse: 0.8444\n",
      "Epoch 3/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.9497 - mae: 0.3750 - mse: 0.9497 - val_accuracy: 0.0024 - val_loss: 0.7338 - val_mae: 0.3476 - val_mse: 0.7338\n",
      "Epoch 4/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0027 - loss: 0.8851 - mae: 0.3707 - mse: 0.8851 - val_accuracy: 0.0024 - val_loss: 0.6755 - val_mae: 0.3273 - val_mse: 0.6755\n",
      "Epoch 5/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.0026 - loss: 0.8606 - mae: 0.3658 - mse: 0.8606 - val_accuracy: 0.0024 - val_loss: 0.6721 - val_mae: 0.3337 - val_mse: 0.6721\n",
      "Epoch 6/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.7926 - mae: 0.3594 - mse: 0.7926 - val_accuracy: 0.0024 - val_loss: 0.6517 - val_mae: 0.3225 - val_mse: 0.6517\n",
      "Epoch 7/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.0030 - loss: 0.8061 - mae: 0.3578 - mse: 0.8061 - val_accuracy: 0.0024 - val_loss: 0.6038 - val_mae: 0.3149 - val_mse: 0.6038\n",
      "Epoch 8/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.0027 - loss: 0.8098 - mae: 0.3557 - mse: 0.8098 - val_accuracy: 0.0024 - val_loss: 0.5677 - val_mae: 0.3082 - val_mse: 0.5677\n",
      "Epoch 9/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0031 - loss: 0.8138 - mae: 0.3541 - mse: 0.8138 - val_accuracy: 0.0024 - val_loss: 0.5585 - val_mae: 0.3136 - val_mse: 0.5585\n",
      "Epoch 10/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0026 - loss: 0.7978 - mae: 0.3544 - mse: 0.7978 - val_accuracy: 0.0024 - val_loss: 0.5822 - val_mae: 0.3140 - val_mse: 0.5822\n",
      "Epoch 11/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.8376 - mae: 0.3621 - mse: 0.8376 - val_accuracy: 0.0024 - val_loss: 0.5582 - val_mae: 0.3075 - val_mse: 0.5582\n",
      "Epoch 12/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0025 - loss: 0.7814 - mae: 0.3521 - mse: 0.7814 - val_accuracy: 0.0024 - val_loss: 0.5433 - val_mae: 0.3149 - val_mse: 0.5433\n",
      "Epoch 13/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0029 - loss: 0.7595 - mae: 0.3454 - mse: 0.7595 - val_accuracy: 0.0024 - val_loss: 0.5536 - val_mae: 0.3158 - val_mse: 0.5536\n",
      "Epoch 14/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0026 - loss: 0.7619 - mae: 0.3458 - mse: 0.7619 - val_accuracy: 0.0024 - val_loss: 0.5527 - val_mae: 0.3087 - val_mse: 0.5527\n",
      "Epoch 15/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.7410 - mae: 0.3436 - mse: 0.7410 - val_accuracy: 0.0024 - val_loss: 0.5732 - val_mae: 0.3084 - val_mse: 0.5732\n",
      "Epoch 16/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.0030 - loss: 0.7155 - mae: 0.3432 - mse: 0.7155 - val_accuracy: 0.0024 - val_loss: 0.5395 - val_mae: 0.2956 - val_mse: 0.5395\n",
      "Epoch 17/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.7386 - mae: 0.3423 - mse: 0.7386 - val_accuracy: 0.0024 - val_loss: 0.5349 - val_mae: 0.3159 - val_mse: 0.5349\n",
      "Epoch 18/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0031 - loss: 0.7197 - mae: 0.3407 - mse: 0.7197 - val_accuracy: 0.0024 - val_loss: 0.5056 - val_mae: 0.3030 - val_mse: 0.5056\n",
      "Epoch 19/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0026 - loss: 0.7512 - mae: 0.3440 - mse: 0.7512 - val_accuracy: 0.0024 - val_loss: 0.4994 - val_mae: 0.3076 - val_mse: 0.4994\n",
      "Epoch 20/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0026 - loss: 0.7194 - mae: 0.3407 - mse: 0.7194 - val_accuracy: 0.0024 - val_loss: 0.5065 - val_mae: 0.2856 - val_mse: 0.5065\n",
      "Epoch 21/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0026 - loss: 0.7349 - mae: 0.3412 - mse: 0.7349 - val_accuracy: 0.0024 - val_loss: 0.5080 - val_mae: 0.2900 - val_mse: 0.5080\n",
      "Epoch 22/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0030 - loss: 0.6850 - mae: 0.3365 - mse: 0.6850 - val_accuracy: 0.0024 - val_loss: 0.5265 - val_mae: 0.3057 - val_mse: 0.5265\n",
      "Epoch 23/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0030 - loss: 0.6558 - mae: 0.3314 - mse: 0.6558 - val_accuracy: 0.0024 - val_loss: 0.5247 - val_mae: 0.2946 - val_mse: 0.5247\n",
      "Epoch 24/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0028 - loss: 0.7036 - mae: 0.3365 - mse: 0.7036 - val_accuracy: 0.0024 - val_loss: 0.4959 - val_mae: 0.2958 - val_mse: 0.4959\n",
      "Epoch 25/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6876 - mae: 0.3349 - mse: 0.6876 - val_accuracy: 0.0024 - val_loss: 0.5138 - val_mae: 0.3079 - val_mse: 0.5138\n",
      "Epoch 26/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0029 - loss: 0.6950 - mae: 0.3345 - mse: 0.6950 - val_accuracy: 0.0024 - val_loss: 0.5029 - val_mae: 0.2995 - val_mse: 0.5029\n",
      "Epoch 27/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0030 - loss: 0.6831 - mae: 0.3342 - mse: 0.6831 - val_accuracy: 0.0024 - val_loss: 0.4605 - val_mae: 0.2862 - val_mse: 0.4605\n",
      "Epoch 28/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0031 - loss: 0.6889 - mae: 0.3362 - mse: 0.6889 - val_accuracy: 0.0024 - val_loss: 0.5060 - val_mae: 0.3041 - val_mse: 0.5060\n",
      "Epoch 29/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0027 - loss: 0.7216 - mae: 0.3409 - mse: 0.7216 - val_accuracy: 0.0024 - val_loss: 0.4905 - val_mae: 0.2957 - val_mse: 0.4905\n",
      "Epoch 30/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.7246 - mae: 0.3402 - mse: 0.7246 - val_accuracy: 0.0024 - val_loss: 0.4849 - val_mae: 0.2902 - val_mse: 0.4849\n",
      "Epoch 31/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.0027 - loss: 0.6708 - mae: 0.3321 - mse: 0.6708 - val_accuracy: 0.0024 - val_loss: 0.5014 - val_mae: 0.2870 - val_mse: 0.5014\n",
      "Epoch 32/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0031 - loss: 0.7031 - mae: 0.3354 - mse: 0.7031 - val_accuracy: 0.0024 - val_loss: 0.4826 - val_mae: 0.2980 - val_mse: 0.4826\n",
      "Epoch 33/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.0030 - loss: 0.6873 - mae: 0.3340 - mse: 0.6873 - val_accuracy: 0.0024 - val_loss: 0.5563 - val_mae: 0.3034 - val_mse: 0.5563\n",
      "Epoch 34/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0025 - loss: 0.6972 - mae: 0.3357 - mse: 0.6972 - val_accuracy: 0.0024 - val_loss: 0.4892 - val_mae: 0.2907 - val_mse: 0.4892\n",
      "Epoch 35/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6909 - mae: 0.3303 - mse: 0.6909 - val_accuracy: 0.0024 - val_loss: 0.4916 - val_mae: 0.2935 - val_mse: 0.4916\n",
      "Epoch 36/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0030 - loss: 0.6601 - mae: 0.3298 - mse: 0.6601 - val_accuracy: 0.0024 - val_loss: 0.4700 - val_mae: 0.2752 - val_mse: 0.4700\n",
      "Epoch 37/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6898 - mae: 0.3326 - mse: 0.6898 - val_accuracy: 0.0024 - val_loss: 0.4566 - val_mae: 0.2929 - val_mse: 0.4566\n",
      "Epoch 38/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0024 - loss: 0.6580 - mae: 0.3329 - mse: 0.6580 - val_accuracy: 0.0024 - val_loss: 0.4820 - val_mae: 0.2858 - val_mse: 0.4820\n",
      "Epoch 39/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6374 - mae: 0.3243 - mse: 0.6374 - val_accuracy: 0.0024 - val_loss: 0.4665 - val_mae: 0.2853 - val_mse: 0.4665\n",
      "Epoch 40/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0027 - loss: 0.6640 - mae: 0.3275 - mse: 0.6640 - val_accuracy: 0.0024 - val_loss: 0.4567 - val_mae: 0.2866 - val_mse: 0.4567\n",
      "Epoch 41/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0030 - loss: 0.6767 - mae: 0.3300 - mse: 0.6767 - val_accuracy: 0.0024 - val_loss: 0.4673 - val_mae: 0.2964 - val_mse: 0.4673\n",
      "Epoch 42/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0025 - loss: 0.6331 - mae: 0.3236 - mse: 0.6331 - val_accuracy: 0.0024 - val_loss: 0.4908 - val_mae: 0.2843 - val_mse: 0.4908\n",
      "Epoch 43/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0027 - loss: 0.6978 - mae: 0.3304 - mse: 0.6978 - val_accuracy: 0.0024 - val_loss: 0.4725 - val_mae: 0.2890 - val_mse: 0.4725\n",
      "Epoch 44/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0029 - loss: 0.6904 - mae: 0.3311 - mse: 0.6904 - val_accuracy: 0.0024 - val_loss: 0.4602 - val_mae: 0.2865 - val_mse: 0.4602\n",
      "Epoch 45/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.0028 - loss: 0.6591 - mae: 0.3267 - mse: 0.6591 - val_accuracy: 0.0024 - val_loss: 0.4741 - val_mae: 0.2781 - val_mse: 0.4741\n",
      "Epoch 46/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0028 - loss: 0.6597 - mae: 0.3281 - mse: 0.6597 - val_accuracy: 0.0024 - val_loss: 0.4727 - val_mae: 0.2940 - val_mse: 0.4727\n",
      "Epoch 47/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.0029 - loss: 0.6410 - mae: 0.3241 - mse: 0.6410 - val_accuracy: 0.0024 - val_loss: 0.4639 - val_mae: 0.2849 - val_mse: 0.4639\n",
      "Epoch 48/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0027 - loss: 0.6601 - mae: 0.3258 - mse: 0.6601 - val_accuracy: 0.0024 - val_loss: 0.4680 - val_mae: 0.2747 - val_mse: 0.4680\n",
      "Epoch 49/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.0028 - loss: 0.6369 - mae: 0.3270 - mse: 0.6369 - val_accuracy: 0.0024 - val_loss: 0.4720 - val_mae: 0.2899 - val_mse: 0.4720\n",
      "Epoch 50/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6249 - mae: 0.3207 - mse: 0.6249 - val_accuracy: 0.0024 - val_loss: 0.4529 - val_mae: 0.2896 - val_mse: 0.4529\n",
      "Epoch 51/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.0026 - loss: 0.6354 - mae: 0.3238 - mse: 0.6354 - val_accuracy: 0.0024 - val_loss: 0.4925 - val_mae: 0.2790 - val_mse: 0.4925\n",
      "Epoch 52/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.0030 - loss: 0.7162 - mae: 0.3291 - mse: 0.7162 - val_accuracy: 0.0024 - val_loss: 0.4417 - val_mae: 0.2987 - val_mse: 0.4417\n",
      "Epoch 53/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.0029 - loss: 0.6510 - mae: 0.3252 - mse: 0.6510 - val_accuracy: 0.0024 - val_loss: 0.4456 - val_mae: 0.2827 - val_mse: 0.4456\n",
      "Epoch 54/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0031 - loss: 0.6681 - mae: 0.3281 - mse: 0.6681 - val_accuracy: 0.0024 - val_loss: 0.5355 - val_mae: 0.2872 - val_mse: 0.5355\n",
      "Epoch 55/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.6381 - mae: 0.3232 - mse: 0.6381 - val_accuracy: 0.0024 - val_loss: 0.4269 - val_mae: 0.2741 - val_mse: 0.4269\n",
      "Epoch 56/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6394 - mae: 0.3256 - mse: 0.6394 - val_accuracy: 0.0024 - val_loss: 0.4534 - val_mae: 0.2899 - val_mse: 0.4534\n",
      "Epoch 57/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0026 - loss: 0.6381 - mae: 0.3180 - mse: 0.6381 - val_accuracy: 0.0024 - val_loss: 0.4879 - val_mae: 0.2912 - val_mse: 0.4879\n",
      "Epoch 58/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.6229 - mae: 0.3217 - mse: 0.6229 - val_accuracy: 0.0024 - val_loss: 0.4569 - val_mae: 0.2760 - val_mse: 0.4569\n",
      "Epoch 59/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - accuracy: 0.0030 - loss: 0.6080 - mae: 0.3189 - mse: 0.6080 - val_accuracy: 0.0024 - val_loss: 0.4385 - val_mae: 0.2751 - val_mse: 0.4385\n",
      "Epoch 60/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0026 - loss: 0.6083 - mae: 0.3220 - mse: 0.6083 - val_accuracy: 0.0024 - val_loss: 0.4530 - val_mae: 0.2773 - val_mse: 0.4530\n",
      "Epoch 61/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.6700 - mae: 0.3229 - mse: 0.6700 - val_accuracy: 0.0024 - val_loss: 0.4506 - val_mae: 0.2920 - val_mse: 0.4506\n",
      "Epoch 62/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6587 - mae: 0.3236 - mse: 0.6587 - val_accuracy: 0.0024 - val_loss: 0.4396 - val_mae: 0.2701 - val_mse: 0.4396\n",
      "Epoch 63/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0029 - loss: 0.6083 - mae: 0.3176 - mse: 0.6083 - val_accuracy: 0.0024 - val_loss: 0.4219 - val_mae: 0.2788 - val_mse: 0.4219\n",
      "Epoch 64/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0030 - loss: 0.5906 - mae: 0.3175 - mse: 0.5906 - val_accuracy: 0.0024 - val_loss: 0.4385 - val_mae: 0.2798 - val_mse: 0.4385\n",
      "Epoch 65/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6684 - mae: 0.3261 - mse: 0.6684 - val_accuracy: 0.0024 - val_loss: 0.4395 - val_mae: 0.2775 - val_mse: 0.4395\n",
      "Epoch 66/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0030 - loss: 0.5974 - mae: 0.3160 - mse: 0.5974 - val_accuracy: 0.0024 - val_loss: 0.4411 - val_mae: 0.2719 - val_mse: 0.4411\n",
      "Epoch 67/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.0026 - loss: 0.6311 - mae: 0.3193 - mse: 0.6311 - val_accuracy: 0.0024 - val_loss: 0.4461 - val_mae: 0.2695 - val_mse: 0.4461\n",
      "Epoch 68/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0027 - loss: 0.6100 - mae: 0.3205 - mse: 0.6100 - val_accuracy: 0.0024 - val_loss: 0.4561 - val_mae: 0.2694 - val_mse: 0.4561\n",
      "Epoch 69/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.6171 - mae: 0.3213 - mse: 0.6171 - val_accuracy: 0.0024 - val_loss: 0.4676 - val_mae: 0.2761 - val_mse: 0.4676\n",
      "Epoch 70/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6161 - mae: 0.3167 - mse: 0.6161 - val_accuracy: 0.0024 - val_loss: 0.4347 - val_mae: 0.2802 - val_mse: 0.4347\n",
      "Epoch 71/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0027 - loss: 0.6121 - mae: 0.3151 - mse: 0.6121 - val_accuracy: 0.0024 - val_loss: 0.4189 - val_mae: 0.2789 - val_mse: 0.4189\n",
      "Epoch 72/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0027 - loss: 0.6006 - mae: 0.3172 - mse: 0.6006 - val_accuracy: 0.0024 - val_loss: 0.4185 - val_mae: 0.2835 - val_mse: 0.4185\n",
      "Epoch 73/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6161 - mae: 0.3193 - mse: 0.6161 - val_accuracy: 0.0024 - val_loss: 0.4272 - val_mae: 0.2855 - val_mse: 0.4272\n",
      "Epoch 74/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0027 - loss: 0.6405 - mae: 0.3239 - mse: 0.6405 - val_accuracy: 0.0024 - val_loss: 0.4200 - val_mae: 0.2804 - val_mse: 0.4200\n",
      "Epoch 75/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - accuracy: 0.0026 - loss: 0.6168 - mae: 0.3187 - mse: 0.6168 - val_accuracy: 0.0024 - val_loss: 0.4334 - val_mae: 0.2736 - val_mse: 0.4334\n",
      "Epoch 76/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.5979 - mae: 0.3175 - mse: 0.5979 - val_accuracy: 0.0024 - val_loss: 0.4430 - val_mae: 0.2647 - val_mse: 0.4430\n",
      "Epoch 77/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0026 - loss: 0.6031 - mae: 0.3184 - mse: 0.6031 - val_accuracy: 0.0024 - val_loss: 0.4196 - val_mae: 0.2839 - val_mse: 0.4196\n",
      "Epoch 78/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6059 - mae: 0.3182 - mse: 0.6059 - val_accuracy: 0.0024 - val_loss: 0.4350 - val_mae: 0.2773 - val_mse: 0.4350\n",
      "Epoch 79/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0026 - loss: 0.6208 - mae: 0.3167 - mse: 0.6208 - val_accuracy: 0.0024 - val_loss: 0.4378 - val_mae: 0.2769 - val_mse: 0.4378\n",
      "Epoch 80/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0031 - loss: 0.5672 - mae: 0.3111 - mse: 0.5672 - val_accuracy: 0.0024 - val_loss: 0.4352 - val_mae: 0.2774 - val_mse: 0.4352\n",
      "Epoch 81/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7ms/step - accuracy: 0.0026 - loss: 0.5898 - mae: 0.3149 - mse: 0.5898 - val_accuracy: 0.0024 - val_loss: 0.4489 - val_mae: 0.2742 - val_mse: 0.4489\n",
      "Epoch 82/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0030 - loss: 0.6036 - mae: 0.3176 - mse: 0.6036 - val_accuracy: 0.0024 - val_loss: 0.4270 - val_mae: 0.2767 - val_mse: 0.4270\n",
      "Epoch 83/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6215 - mae: 0.3175 - mse: 0.6215 - val_accuracy: 0.0024 - val_loss: 0.4289 - val_mae: 0.2786 - val_mse: 0.4289\n",
      "Epoch 84/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0030 - loss: 0.6096 - mae: 0.3170 - mse: 0.6096 - val_accuracy: 0.0024 - val_loss: 0.4288 - val_mae: 0.2825 - val_mse: 0.4288\n",
      "Epoch 85/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.6109 - mae: 0.3186 - mse: 0.6109 - val_accuracy: 0.0024 - val_loss: 0.4203 - val_mae: 0.2705 - val_mse: 0.4203\n",
      "Epoch 86/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0029 - loss: 0.6274 - mae: 0.3168 - mse: 0.6274 - val_accuracy: 0.0024 - val_loss: 0.4324 - val_mae: 0.2733 - val_mse: 0.4324\n",
      "Epoch 87/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.5865 - mae: 0.3163 - mse: 0.5865 - val_accuracy: 0.0024 - val_loss: 0.4311 - val_mae: 0.2758 - val_mse: 0.4311\n",
      "Epoch 88/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.5970 - mae: 0.3146 - mse: 0.5970 - val_accuracy: 0.0024 - val_loss: 0.4333 - val_mae: 0.2708 - val_mse: 0.4333\n",
      "Epoch 89/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.0025 - loss: 0.5783 - mae: 0.3121 - mse: 0.5783 - val_accuracy: 0.0024 - val_loss: 0.4166 - val_mae: 0.2854 - val_mse: 0.4166\n",
      "Epoch 90/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.6345 - mae: 0.3192 - mse: 0.6345 - val_accuracy: 0.0024 - val_loss: 0.4333 - val_mae: 0.2733 - val_mse: 0.4333\n",
      "Epoch 91/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0027 - loss: 0.6074 - mae: 0.3191 - mse: 0.6074 - val_accuracy: 0.0024 - val_loss: 0.4641 - val_mae: 0.2871 - val_mse: 0.4641\n",
      "Epoch 92/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7ms/step - accuracy: 0.0027 - loss: 0.5630 - mae: 0.3125 - mse: 0.5630 - val_accuracy: 0.0024 - val_loss: 0.4262 - val_mae: 0.2667 - val_mse: 0.4262\n",
      "Epoch 93/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0026 - loss: 0.5696 - mae: 0.3132 - mse: 0.5696 - val_accuracy: 0.0024 - val_loss: 0.3980 - val_mae: 0.2756 - val_mse: 0.3980\n",
      "Epoch 94/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.6147 - mae: 0.3179 - mse: 0.6147 - val_accuracy: 0.0024 - val_loss: 0.4005 - val_mae: 0.2692 - val_mse: 0.4005\n",
      "Epoch 95/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0030 - loss: 0.5953 - mae: 0.3146 - mse: 0.5953 - val_accuracy: 0.0024 - val_loss: 0.4131 - val_mae: 0.2684 - val_mse: 0.4131\n",
      "Epoch 96/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.5932 - mae: 0.3181 - mse: 0.5932 - val_accuracy: 0.0024 - val_loss: 0.4695 - val_mae: 0.2842 - val_mse: 0.4695\n",
      "Epoch 97/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0023 - loss: 0.5833 - mae: 0.3140 - mse: 0.5833 - val_accuracy: 0.0024 - val_loss: 0.4305 - val_mae: 0.2772 - val_mse: 0.4305\n",
      "Epoch 98/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.5983 - mae: 0.3162 - mse: 0.5983 - val_accuracy: 0.0024 - val_loss: 0.4300 - val_mae: 0.2785 - val_mse: 0.4300\n",
      "Epoch 99/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.0029 - loss: 0.6083 - mae: 0.3173 - mse: 0.6083 - val_accuracy: 0.0024 - val_loss: 0.4226 - val_mae: 0.2804 - val_mse: 0.4226\n",
      "Epoch 100/100\n",
      "\u001b[1m3530/3530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.0027 - loss: 0.6004 - mae: 0.3170 - mse: 0.6004 - val_accuracy: 0.0024 - val_loss: 0.4273 - val_mae: 0.2838 - val_mse: 0.4273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fa7584ea750>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_valid, y_valid), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0026 - loss: 0.4073 - mae: 0.2742 - mse: 0.4073\n",
      "[0.42726361751556396, 0.0023545240983366966, 0.28378382325172424, 0.42726361751556396]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_valid, y_valid)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Result file saved as 'result.csv'\n",
      "Submission file saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "predictions = model.predict(X_test_transformed)\n",
    "\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    id_col[0]: pd.to_datetime(test_data[id_col[0]]).dt.strftime(\"%m/%d/%Y\"),\n",
    "    id_col[1]: test_data[id_col[1]],\n",
    "    # \"target\": data[target_col],\n",
    "    \"prediction\": predictions.flatten()\n",
    "})\n",
    "\n",
    "result.to_csv('result.csv', index=False)\n",
    "print(\"Result file saved as 'result.csv'\")\n",
    "\n",
    "result.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "# Compare predictions with actual values\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel(\"Actual Sales\")\n",
    "plt.ylabel(\"Predicted Sales\")\n",
    "plt.title(\"Actual vs. Predicted Sales\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(8, input_shape=[None, 1], return_sequences=True))\n",
    "model2.add(LSTM(4, input_shape=[None, 1]))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(loss=\"huber_loss\", optimizer='adam')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novartis-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
